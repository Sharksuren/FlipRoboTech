{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all the required libraries\n",
    "import pandas as pd\n",
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException, ElementClickInterceptedException  , ElementNotInteractableException        \n",
    "from selenium.common import exceptions as ex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape the details of most viewed videos on YouTube from Wikipedia:\n",
    "Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos/\n",
    "You need to find following details:\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(executable_path='C:\\\\Users\\\\suren\\\\FlipRobo\\\\Micro-Credit-Project\\\\chromedriver.exe')\n",
    "url_='https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "driver.get(url_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating empty list to scrap the details required\n",
    "\n",
    "Rank=[]\n",
    "Name=[]\n",
    "Artist=[]\n",
    "Upload_date=[]\n",
    "Views_in_billions=[]\n",
    "\n",
    "#creating webelements for each data required\n",
    "rank_element=driver.find_elements(By.XPATH,'//caption[contains(text(),\"30 most-viewed \")]/parent::table/tbody/tr/td[1]')\n",
    "name_element=driver.find_elements(By.XPATH,'//caption[contains(text(),\"30 most-viewed \")]/parent::table/tbody/tr/td[2]')\n",
    "artist_element=driver.find_elements(By.XPATH,'//caption[contains(text(),\"30 most-viewed \")]/parent::table/tbody/tr/td[3]')\n",
    "date_element=driver.find_elements(By.XPATH,'//caption[contains(text(),\"30 most-viewed \")]/parent::table/tbody/tr/td[5]')\n",
    "view_element=driver.find_elements(By.XPATH,'//caption[contains(text(),\"30 most-viewed \")]/parent::table/tbody/tr/td[4]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Looping rank element and appending the scrapped data into the list\n",
    "\n",
    "for i in rank_element:\n",
    "    Rank.append(i.text.replace('.',''))\n",
    "    \n",
    "for i in name_element:\n",
    "    Name.append(i.text)\n",
    "\n",
    "for i in artist_element:\n",
    "    Artist.append(i.text)\n",
    "    \n",
    "for i in date_element:\n",
    "    Upload_date.append(i.text)\n",
    "    \n",
    "for i in view_element:\n",
    "    Views_in_billions.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 30, 30, 30, 30)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Name), len(Rank), len(Artist), len(Upload_date), len(Views_in_billions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape the details team Indiaâ€™s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:\n",
    "A) Match title (I.e. 1st ODI)\n",
    "B) Series\n",
    "C) Place\n",
    "D) Date\n",
    "E) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(executable_path='C:\\\\Users\\\\suren\\\\FlipRobo\\\\Micro-Credit-Project\\\\chromedriver.exe')\n",
    "\n",
    "#Launching URL\n",
    "url_='https://www.bcci.tv/'\n",
    "driver.get(url_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Moving to international drop down by hovering and followed by clicking on Fixtures\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "\n",
    "action = ActionChains(driver)\n",
    "\n",
    "International = driver.find_element_by_xpath('//div[contains(text(),\"International\")]')\n",
    "Fixture = driver.find_element_by_xpath('//div[contains(text(),\"International\")]//parent::li//ul//a[contains(text(),\"Fixtures\")]')\n",
    "  \n",
    "ActionChains(driver).move_to_element(International).click(Fixture).perform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Appending match formats availble in the site\n",
    "\n",
    "formats=[]\n",
    "\n",
    "try:\n",
    "    time.sleep(3)\n",
    "    driver.find_element(By.XPATH,'//div[@data-dropdown=\"matchTypes\"]//div[2]').click()\n",
    "    format_element=driver.find_elements(By.XPATH,'//div[@data-dropdown=\"matchTypes\"]//li/span')\n",
    "\n",
    "    \n",
    "except StaleElementReferenceException as e:\n",
    "    print(\"Exception occured in finding the match formats\")\n",
    "    driver.find_element(By.XPATH,'//*[@id=\"TestAlexFilter\"]').click()\n",
    "    format_element=driver.find_elements(By.XPATH,'//div[@data-dropdown=\"matchTypes\"]//li/span')\n",
    "\n",
    "for i in format_element:\n",
    "    formats.append(i.get_attribute(\"title\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['All Formats', 'TEST', 'ODI', 'T20I']"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "Match_title=[]\n",
    "Series=[]\n",
    "Place=[]\n",
    "Date=[]\n",
    "Time=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "exceptions occured Message: element not interactable\n",
      "  (Session info: chrome=91.0.4472.124)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loop_max=len(formats)+1\n",
    "print(loop_max)\n",
    "for i in range(1,loop_max):\n",
    "    driver.find_element(By.XPATH,'//div[@data-dropdown=\"matchTypes\"]//div[2]').click()\n",
    "    xpath_str='//div[@data-dropdown=\"matchTypes\"]//li['+str(i)+']'\n",
    "    try:\n",
    "        time.sleep(5)\n",
    "        driver.find_element(By.XPATH,xpath_str).click()\n",
    "        \n",
    "    except ElementNotInteractableException as ec:\n",
    "        time.sleep(3)\n",
    "        print('exceptions occured' , ec)\n",
    "\n",
    "    #appending date and time\n",
    "    time.sleep(1)\n",
    "    for j in driver.find_elements(By.XPATH,'//div[@class=\"fixture__datetime desktop-only\"]'):\n",
    "        full_dt=j.text.split()\n",
    "        Date.append(full_dt[1]+'-'+full_dt[2])\n",
    "        Time.append(full_dt[-2]+'-'+full_dt[-1])\n",
    "        \n",
    "    #appending place\n",
    "    time.sleep(1)\n",
    "    for j in (0,len(Date)):\n",
    "        try:\n",
    "            place_element=driver.find_element(By.XPATH,'//div[@class=\"fixture__description u-unskewed-text\"]//p/span')\n",
    "            Place.append(place_element.text)\n",
    "        except StaleElementReferenceException as se:\n",
    "            print(se)\n",
    "            Place.append('NaN')\n",
    "        \n",
    "    #appending series\n",
    "    time.sleep(1)\n",
    "    for j in (0,len(Date)):\n",
    "        try:\n",
    "            Series_element=driver.find_element(By.XPATH,'//div[@class=\"fixture__description u-unskewed-text\"]//p/strong')\n",
    "            Series.append(Series_element.text)\n",
    "        except StaleElementReferenceException as se:\n",
    "            print(se)\n",
    "            Series.append('NaN')\n",
    "        \n",
    "        \n",
    "    #appending match title\n",
    "    time.sleep(1)\n",
    "    for j in (0,len(Date)):\n",
    "        try:\n",
    "            title_element=driver.find_element(By.XPATH,'//span[@class=\"u-unskewed-text fixture__format\"]')\n",
    "            Match_title.append(title_element.text)\n",
    "        except StaleElementReferenceException as se:\n",
    "            print(se)\n",
    "            Match_title.append('NaN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 11, 8, 8, 8)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Date), len(Time), len(Match_title), len(Place), len(Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape the details of selenium exception from guru99.com.\n",
    "Url = https://www.guru99.com/\n",
    "You need to find following details:\n",
    "A) Name\n",
    "B) Description\n",
    "Note: - From guru99 home page you have to reach to selenium exception handling page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(executable_path='C:\\\\Users\\\\suren\\\\FlipRobo\\\\Micro-Credit-Project\\\\chromedriver.exe')\n",
    "\n",
    "#Launching URL\n",
    "url_='https://www.guru99.com/'\n",
    "driver.get(url_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#navigating to exception handling page\n",
    "driver.find_element(By.XPATH,'//*[@id=\"java_technologies\"]/li[3]/a').click()\n",
    "driver.find_element(By.XPATH,'//a[@href=\"/exception-handling-selenium.html\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dumy list to append the details\n",
    "exception_name=[]\n",
    "Description=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "#appending exception name\n",
    "for i in driver.find_elements(By.XPATH,'//table[@class=\"table table-striped\"]//td[1]'):\n",
    "    exception_name.append(i.text)\n",
    "\n",
    "#appending exception description\n",
    "for i in driver.find_elements(By.XPATH,'//table[@class=\"table table-striped\"]//td[2]'):\n",
    "    Description.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42, 42)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(exception_name), len(Description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:\n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP at current price (19-20)\n",
    "D) GSDP at current price (18-19)\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.alert import Alert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(executable_path='C:\\\\Users\\\\suren\\\\FlipRobo\\\\Micro-Credit-Project\\\\chromedriver.exe')\n",
    "\n",
    "#Launching URL\n",
    "url_='http://statisticstimes.com/'\n",
    "driver.get(url_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executed try block\n"
     ]
    }
   ],
   "source": [
    "#navigating to economy and followed by india\n",
    "\n",
    "Economy = driver.find_element_by_xpath('//button[contains(text(),\"Economy\")]')\n",
    "india = driver.find_element_by_xpath('//a[@href=\"economy/india-statistics.php\"]')\n",
    "  \n",
    "ActionChains(driver).move_to_element(Economy).click(india).perform()\n",
    "\n",
    "#Handling pop ups\n",
    "time.sleep(3)\n",
    "try:\n",
    "    #driver.find_element(By.XPATH,'//div[@aria-label=\"Close ad\"]').click()\n",
    "    #element=driver.find_element(By.XPATH,'//div[@aria-label=\"Close ad\"]').click()\n",
    "    #driver.execute_script(\"arguments[0].click();\", element)\n",
    "    print(\"Executed try block\")\n",
    "except NoSuchElementException as ns:\n",
    "    #driver.find_element(By.XPATH,'//div[@id=\"dismiss-button\"]').click()\n",
    "    print(ns)\n",
    "    \n",
    "#navigating to DGP of indian states\n",
    "\n",
    "#driver.find_element_by_xpath('//a[@href=\"india/indian-states-gdp.php\"]').click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank=[]\n",
    "State=[]\n",
    "GSDP_Current_18=[]\n",
    "GSDP_Current_19=[]\n",
    "Share=[]\n",
    "GDP_in_billions=[]\n",
    "\n",
    "for i in driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]//td[1]'):\n",
    "    Rank.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]//td[2]'):\n",
    "    State.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]//td[4]'):\n",
    "    GSDP_Current_18.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]//td[3]'):\n",
    "    GSDP_Current_19.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]//td[5]'):\n",
    "    Share.append(i.text)\n",
    "    \n",
    "for i in driver.find_elements(By.XPATH,'//table[@id=\"table_id\"]//td[6]'):\n",
    "    GDP_in_billions.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used\n",
    "ASSIGNMENT\n",
    "Note: - From the home page you have to click on the trending option from Explore menu through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(executable_path='C:\\\\Users\\\\suren\\\\FlipRobo\\\\Micro-Credit-Project\\\\chromedriver.exe')\n",
    "\n",
    "#Launching URL\n",
    "url_='https://github.com/'\n",
    "driver.get(url_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "#navigating to explore and followed by trending\n",
    "\n",
    "explore = driver.find_element_by_xpath('//summary[contains(text(),\"Explore\")]//parent::details//parent::li')\n",
    "trending = driver.find_element_by_xpath('//a[@href=\"/trending\"]')\n",
    "try:\n",
    "    time.sleep(2)\n",
    "    ActionChains(driver).move_to_element(explore).click(trending).perform()\n",
    "except ElementNotInteractableException as en:\n",
    "    print(en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list to scrap the details\n",
    "\n",
    "repo_name=[]\n",
    "repo_des=[]\n",
    "contributors=[]\n",
    "Language=[]\n",
    "\n",
    "#appending repo name\n",
    "time.sleep(2)\n",
    "for i in driver.find_elements(By.XPATH,'//h1[@class=\"h3 lh-condensed\"]/a'):\n",
    "    repo_name.append(i.text)\n",
    "\n",
    "time.sleep(2)\n",
    "#appendign repo description\n",
    "for i in driver.find_elements(By.XPATH,'//article[@class=\"Box-row\"]/p'):\n",
    "    repo_des.append(i.text)\n",
    "\n",
    "time.sleep(2)\n",
    "#appending contributors\n",
    "for i in driver.find_elements(By.XPATH,'//span[contains(text(),\"Built by\")]'):\n",
    "    contributors.append(i.text)\n",
    "\n",
    "time.sleep(2)\n",
    "#appending language    \n",
    "for i in driver.find_elements(By.XPATH,'//span[@itemprop=\"programmingLanguage\"]'):\n",
    "    if i.text is None:\n",
    "        Language.append(\"-\")\n",
    "    else:\n",
    "        Language.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape the details of top 100 songs on billboard.com.\n",
    "Url = https://www.billboard.com/\n",
    "You have to find the following details:\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(executable_path='C:\\\\Users\\\\suren\\\\FlipRobo\\\\Micro-Credit-Project\\\\chromedriver.exe')\n",
    "\n",
    "#Launching URL\n",
    "url_='https://www.billboard.com/'\n",
    "driver.get(url_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "#navigating to charts and followed by hot-100\n",
    "\n",
    "try:\n",
    "    chart = driver.find_element_by_xpath('//li[@aria-controls=\"menu-charts-mobile\"]')\n",
    "    hot_100 = driver.find_element_by_xpath('//a[@href=\"/charts/hot-100\"]//parent::li')\n",
    "    try:\n",
    "        time.sleep(2)\n",
    "        ActionChains(driver).move_to_element(chart).click(hot_100).perform()\n",
    "    except ElementNotInteractableException as en:\n",
    "        print(en)\n",
    "    \n",
    "except NoSuchElementException as ns:\n",
    "    chart = driver.find_element_by_xpath('//a[@href=\"/charts/hot-100\"]').click()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "song_name=[]\n",
    "Artist_name=[]\n",
    "last_week_rank=[]\n",
    "peak_rank=[]\n",
    "weeks_on_board=[]\n",
    "\n",
    "\n",
    "time.sleep(2)\n",
    "#appending song name    \n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"chart-element__information__song text--truncate color--primary\"]'):\n",
    "    if i.text is None:\n",
    "        song_name.append(\"-\")\n",
    "    else:\n",
    "        song_name.append(i.text)\n",
    "        \n",
    "time.sleep(2)\n",
    "#appending artist name    \n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"chart-element__information__artist text--truncate color--secondary\"]'):\n",
    "    if i.text is None:\n",
    "        Artist_name.append(\"-\")\n",
    "    else:\n",
    "        Artist_name.append(i.text)\n",
    "        \n",
    "time.sleep(2)\n",
    "#appending lask week rank    \n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"chart-element__meta text--center color--secondary text--last\"]'):\n",
    "    if i.text is None:\n",
    "        last_week_rank.append(\"-\")\n",
    "    else:\n",
    "        last_week_rank.append(i.text)\n",
    "        \n",
    "time.sleep(2)\n",
    "#appending peak rank    \n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"chart-element__meta text--center color--secondary text--peak\"]'):\n",
    "    if i.text is None:\n",
    "        peak_rank.append(\"-\")\n",
    "    else:\n",
    "        peak_rank.append(i.text)\n",
    "        \n",
    "time.sleep(2)\n",
    "#appending weeks on board    \n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"chart-element__meta text--center color--secondary text--week\"]'):\n",
    "    if i.text is None:\n",
    "        weeks_on_board.append(\"-\")\n",
    "    else:\n",
    "        weeks_on_board.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100, 100, 100)"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(song_name),len(Artist_name),len(last_week_rank),len(peak_rank),len(weeks_on_board),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape the details of Data science recruiters from naukri.com.\n",
    "Url = https://www.naukri.com/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Designation\n",
    "C) Company\n",
    "D) Skills they hire for\n",
    "E) Location\n",
    "Note: - From naukri.com homepage click on the recruiters option and the on the search pane type Data science and\n",
    "click on search. All this should be done through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CDwindow-21C010BD1B4922A544002C0C4E320268\n",
      "CDwindow-63DDE159E37ED9467E07CDE484192593\n"
     ]
    }
   ],
   "source": [
    "driver=webdriver.Chrome(executable_path='C:\\\\Users\\\\suren\\\\FlipRobo\\\\Micro-Credit-Project\\\\chromedriver.exe')\n",
    "\n",
    "#Launching URL\n",
    "url_='https://www.naukri.com/'\n",
    "driver.get(url_)\n",
    "\n",
    "#capturing first window id to differenciate\n",
    "window_before = driver.window_handles[0]\n",
    "print(window_before)   \n",
    "\n",
    "#launching recruiters link\n",
    "driver.find_element(By.XPATH,'//div[text()=\"Recruiters\"]').click()\n",
    "\n",
    "#capturing new window created\n",
    "new_window = driver.window_handles[-1]\n",
    "print(new_window)\n",
    "\n",
    "#switing the driver control to new window\n",
    "time.sleep(2)\n",
    "\n",
    "driver.switch_to.window(new_window)\n",
    "\n",
    "#entering search key\n",
    "time.sleep(2)\n",
    "driver.find_element(By.XPATH,'//input[@placeholder=\"Skills, Designations, Companies\"]').send_keys(\"Data Science\")\n",
    "#clicking on search key\n",
    "try:\n",
    "    driver.find_element(By.XPATH,'//form[@data-error-message=\"Please enter Keywords or Location to search\"]//button').click()\n",
    "except ElementClickInterceptedException as eci:\n",
    "    print(eci)\n",
    "    driver.find_element(By.XPATH,'//input[@placeholder=\"Skills, Designations, Companies\"]').send_keys(Keys.ENTER)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "name=[]\n",
    "designation=[]\n",
    "company=[]\n",
    "skills=[]\n",
    "location=[]\n",
    "\n",
    "\n",
    "time.sleep(2)\n",
    "#appending name    \n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"fl ellipsis\"]'):\n",
    "    if i.text is None:\n",
    "        name.append(\"-\")\n",
    "    else:\n",
    "        name.append(i.text)\n",
    "        \n",
    "time.sleep(2)\n",
    "#appending designation   \n",
    "for i in driver.find_elements(By.XPATH,'//span[@class=\"ellipsis clr\"]'):\n",
    "    if i.text is None:\n",
    "        designation.append(\"-\")\n",
    "    else:\n",
    "        designation.append(i.text)\n",
    "        \n",
    "time.sleep(2)\n",
    "#appending comapny   \n",
    "for i in driver.find_elements(By.XPATH,'//p[@class=\"highlightable\"]//a[2]'):\n",
    "    if i.text is None:\n",
    "        company.append(\"-\")\n",
    "    else:\n",
    "        company.append(i.text)\n",
    "        \n",
    "time.sleep(2)\n",
    "#appending skills    \n",
    "for i in driver.find_elements(By.XPATH,'//div[@class=\"hireSec highlightable\"]'):\n",
    "    if i.text is None:\n",
    "        skills.append(\"-\")\n",
    "    else:\n",
    "        skills.append(i.text)\n",
    "        \n",
    "time.sleep(2)\n",
    "#appending location    \n",
    "for i in driver.find_elements(By.XPATH,'//p[@class=\"highlightable\"]/span[2]/small'):\n",
    "    if i.text is None:\n",
    "        location.append(\"-\")\n",
    "    else:\n",
    "        location.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Scrape the details of Highest selling novels.\n",
    "Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-greycompare/\n",
    "You have to find the following details:\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "driver=webdriver.Chrome(executable_path='C:\\\\Users\\\\suren\\\\FlipRobo\\\\Micro-Credit-Project\\\\chromedriver.exe')\n",
    "\n",
    "#Launching URL\n",
    "url_=' https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-greycompare/'\n",
    "driver.get(url_)\n",
    "\n",
    "Getting 404 error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Scrape the details most watched tv series of all time from imdb.com.\n",
    " Url = https://www.imdb.com/list/ls095964455/\n",
    "You have to find the following details:\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(executable_path='C:\\\\Users\\\\suren\\\\FlipRobo\\\\Micro-Credit-Project\\\\chromedriver.exe')\n",
    "\n",
    "#Launching URL \n",
    "url_='https://www.imdb.com/list/ls095964455/'\n",
    "driver.get(url_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list to append the details\n",
    "\n",
    "name=[]\n",
    "year_span=[]\n",
    "genre=[]\n",
    "run_time=[]\n",
    "rating=[]\n",
    "vote=[]\n",
    "\n",
    "\n",
    "#appending name\n",
    "try:\n",
    "    Name = driver.find_elements_by_xpath('//h3[@class=\"lister-item-header\"]//a')  \n",
    "    for i in Name:\n",
    "        name.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    name.append('-')\n",
    "\n",
    "\n",
    "#appending year\n",
    "try:\n",
    "    Year = driver.find_elements_by_xpath('//span[@class=\"lister-item-year text-muted unbold\"]')\n",
    "    for i in Year:\n",
    "        year_span.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    year_span.append('-')\n",
    "    \n",
    "#appending genre\n",
    "try:\n",
    "    Genre = driver.find_elements_by_xpath('//span[@class=\"genre\"]')\n",
    "    for i in Genre:\n",
    "        genre.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    genre.append('-')\n",
    "    \n",
    "#appending runtime\n",
    "try:\n",
    "    time = driver.find_elements_by_xpath('//span[@class=\"runtime\"]')\n",
    "    for i in time:\n",
    "        run_time.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    run_time.append('-')\n",
    "    \n",
    "#appending rating\n",
    "try:\n",
    "    Rate = driver.find_elements_by_xpath('//div[@class=\"ipl-rating-star small\"]/span[2]') \n",
    "    for i in Rate:\n",
    "        rating.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    rating.append('-')\n",
    "    \n",
    "#appending vote\n",
    "try:\n",
    "    Vote = driver.find_elements_by_xpath('//div[@class=\"lister-item-content\"]//p[4]//span[2]') \n",
    "    for i in Vote:\n",
    "        vote.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    vote.append('-')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100, 100, 100, 100)"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(name),len(year_span),len(genre),len(run_time),len(rating),len(vote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Details of Datasets from UCI machine learning repositories.\n",
    " Url = https://archive.ics.uci.edu/\n",
    " You have to find the following details:\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute\n",
    "G) Year\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver=webdriver.Chrome(executable_path='C:\\\\Users\\\\suren\\\\FlipRobo\\\\Micro-Credit-Project\\\\chromedriver.exe')\n",
    "\n",
    "#Launching URL \n",
    "url_='https://archive.ics.uci.edu/'\n",
    "driver.get(url_)\n",
    "\n",
    "#navigating to show all data set\n",
    "driver.find_element(By.XPATH,'//span[@class=\"whitetext\"]//a[@href=\"datasets.php\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list to append the details\n",
    "Dataset_name=[]\n",
    "Data_type=[]\n",
    "Task=[]\n",
    "Attribute_type=[]\n",
    "No_of_instances=[]\n",
    "No_of_attribute=[]\n",
    "year=[]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list=driver.find_elements(By.XPATH,'//table[@border=\"1\"]//p')\n",
    "count=1\n",
    "for i in new_list:\n",
    "    if count==1:\n",
    "        Dataset_name.append(i.text)\n",
    "        count=count+1\n",
    "    elif count ==2:\n",
    "        Data_type.append(i.text)\n",
    "        count=count+1\n",
    "    elif count ==3:\n",
    "        Task.append(i.text)\n",
    "        count=count+1\n",
    "    elif count ==4:\n",
    "        Attribute_type.append(i.text)\n",
    "        count=count+1\n",
    "    elif count ==5:\n",
    "        No_of_instances.append(i.text)\n",
    "        count=count+1\n",
    "    elif count ==6:\n",
    "        No_of_attribute.append(i.text)\n",
    "        count=count+1\n",
    "    else:\n",
    "        year.append(i.text)\n",
    "        count=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(589, 589, 589, 589, 589, 589, 589)"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Dataset_name),len(Data_type),len(Task),len(Attribute_type),len(No_of_instances),len(No_of_attribute),len(year)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
