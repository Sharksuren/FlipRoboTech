{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries needed to perform selenium task\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import time\n",
    "time.sleep(5)\n",
    "\n",
    "#importing pandas to creaate a data frame with the details scrapped\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating web driver object\n",
    "driver=webdriver.Chrome(executable_path='C:\\\\Users\\\\suren\\\\FlipRobo\\\\Micro-Credit-Project\\\\chromedriver.exe')\n",
    "\n",
    "#defining url\n",
    "url_='https://www.naukri.com/'\n",
    "\n",
    "#initialising driver\n",
    "driver.get(url_)\n",
    "\n",
    "#maximizing the window\n",
    "driver.maximize_window()\n",
    "\n",
    "#Finding the skill,qualification,company field and storing it into a variable\n",
    "search_box=driver.find_element(By.XPATH,'//input[@id=\"qsb-keyword-sugg\"]')\n",
    "\n",
    "#definign key word to search and Sending key word to search field\n",
    "key_word = 'Data Analyst'\n",
    "search_box.send_keys(key_word)\n",
    "\n",
    "#Finding the location field and storing it into a variable\n",
    "location_box=driver.find_element(By.XPATH,'//input[@id=\"qsb-location-sugg\"]')\n",
    "\n",
    "#definign location and sending it to location field\n",
    "location = 'Bangalore'\n",
    "location_box.send_keys(location)\n",
    "\n",
    "#clicking on search button\n",
    "driver.find_element(By.XPATH,'//div[@class=\"search-btn\"]/button').click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list to append the details we scrap\n",
    "job_title =[]\n",
    "job_location =[]\n",
    "company_name=[]\n",
    "experience_required=[]\n",
    "\n",
    "#getting xpath for each data and storing them in avariable\n",
    "title=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "location=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]/span')\n",
    "company=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "experience=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]/span')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looping title to restrict the counto to first 10 with indexing\n",
    "for i in title[0:10]:\n",
    "    job_title.append(i.text)\n",
    "    \n",
    "#looping location to restrict the count to first 10 with indexing\n",
    "for i in location[0:10]:\n",
    "    job_location.append(i.text)\n",
    "\n",
    "#looping compny name to restrict the count to first 10 with indexing\n",
    "for i in company[0:10]:\n",
    "    company_name.append(i.text)\n",
    "    \n",
    "#looping experience to restrict the counto to first 10 with indexing\n",
    "for i in experience[0:10]:\n",
    "    experience_required.append(i.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_data=pd.DataFrame({})\n",
    "job_data['job_title']=job_title\n",
    "job_data['job_location']=job_location\n",
    "job_data['company_name']=company_name\n",
    "job_data['experience_required']=experience_required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [job_title, job_location, company_name, experience_required]\n",
       "Index: []"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#closing the driver\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXCERCISE II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location,\n",
    "company_name, full job-description. You have to scrape first 10 jobs data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating web driver object\n",
    "driver=webdriver.Chrome(executable_path='C:\\\\Users\\\\suren\\\\FlipRobo\\\\Micro-Credit-Project\\\\chromedriver.exe')\n",
    "\n",
    "#defining url\n",
    "url_='https://www.naukri.com/'\n",
    "\n",
    "#initialising driver\n",
    "driver.get(url_)\n",
    "\n",
    "#maximizing the window\n",
    "driver.maximize_window()\n",
    "\n",
    "#Finding the skill,qualification,company field and storing it into a variable\n",
    "search_box=driver.find_element(By.XPATH,'//input[@id=\"qsb-keyword-sugg\"]')\n",
    "\n",
    "#definign key word to search and Sending key word to search field\n",
    "key_word = 'Data Scientist'\n",
    "search_box.send_keys(key_word)\n",
    "\n",
    "#Finding the location field and storing it into a variable\n",
    "location_box=driver.find_element(By.XPATH,'//input[@id=\"qsb-location-sugg\"]')\n",
    "\n",
    "#definign location and sending it to location field\n",
    "location = 'Bangalore'\n",
    "location_box.send_keys(location)\n",
    "\n",
    "#clicking on search button\n",
    "driver.find_element(By.XPATH,'//div[@class=\"search-btn\"]/button').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list to append the details we scrap\n",
    "job_title_ds =[]\n",
    "job_location_ds =[]\n",
    "company_name_ds=[]\n",
    "job_description_ds=[]\n",
    "job_des_url=[]\n",
    "\n",
    "#getting xpath for each data and storing them in avariable\n",
    "title=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "location=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]/span')\n",
    "company=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looping title to restrict the counto to first 10 with indexing\n",
    "for i in title[0:10]:\n",
    "    job_title_ds.append(i.text)\n",
    "    \n",
    "#looping location to restrict the count to first 10 with indexing\n",
    "for i in location[0:10]:\n",
    "    job_location_ds.append(i.text)\n",
    "\n",
    "#looping compny name to restrict the count to first 10 with indexing\n",
    "for i in company[0:10]:\n",
    "    company_name_ds.append(i.text)\n",
    "    \n",
    "#appending url of each job to retrieve full job description\n",
    "for i in title[0:10]:\n",
    "    job_des_url.append(i.get_attribute('href'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieving full job description by loding each URL\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "for i in job_des_url:\n",
    "    driver.get(i)\n",
    "    try:\n",
    "        job_description_ds.append(driver.find_element_by_xpath('//section[@class=\"job-desc\"]').text)\n",
    "    except NoSuchElementException as e:\n",
    "        print('Exeception occured ',e)\n",
    "        job_description_ds.append(driver.find_element_by_xpath('//div[@class=\"nConfig_textblock \"]').text) \n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0, 0, 0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_title_ds) , len(job_location_ds) , len(company_name_ds) , len(job_description_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_job=pd.DataFrame({})\n",
    "full_job['job_title_ds']=job_title_ds\n",
    "full_job['job_location_ds']=job_location_ds\n",
    "full_job['company_name_ds']=company_name_ds\n",
    "full_job['job_description_ds']=job_description_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title_ds</th>\n",
       "      <th>job_location_ds</th>\n",
       "      <th>company_name_ds</th>\n",
       "      <th>job_description_ds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [job_title_ds, job_location_ds, company_name_ds, job_description_ds]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_job.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXCERCISE III"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating web driver object\n",
    "driver=webdriver.Chrome(executable_path='C:\\\\Users\\\\suren\\\\FlipRobo\\\\Micro-Credit-Project\\\\chromedriver.exe')\n",
    "\n",
    "#defining url\n",
    "url_='https://www.naukri.com/'\n",
    "\n",
    "#initialising driver\n",
    "driver.get(url_)\n",
    "\n",
    "#maximizing the window\n",
    "driver.maximize_window()\n",
    "\n",
    "#Finding the skill,qualification,company field and storing it into a variable\n",
    "search_box=driver.find_element(By.XPATH,'//input[@id=\"qsb-keyword-sugg\"]')\n",
    "\n",
    "#definign key word to search and Sending key word to search field\n",
    "key_word = 'Data Scientist'\n",
    "search_box.send_keys(key_word)\n",
    "\n",
    "#clicking on search button\n",
    "driver.find_element(By.XPATH,'//div[@class=\"search-btn\"]/button').click()\n",
    "\n",
    "#selecting location from filter\n",
    "time.sleep(5)\n",
    "driver.find_element(By.XPATH,'//label[@for=\"chk-Delhi / NCR-cityTypeGid-\"]/i').click()\n",
    "\n",
    "#selecting salary range from filter\n",
    "time.sleep(5)\n",
    "driver.find_element(By.XPATH,'//label[@for=\"chk-3-6 Lakhs-ctcFilter-\"]/i').click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list to append the details we scrap\n",
    "job_title_fil =[]\n",
    "job_location_fil =[]\n",
    "company_name_fil=[]\n",
    "experience_required_fil=[]\n",
    "\n",
    "\n",
    "#getting xpath for each data and storing them in avariable\n",
    "title=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "location=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]/span')\n",
    "company=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "experience=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]/span')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looping title to restrict the counto to first 10 with indexing\n",
    "for i in title[0:10]:\n",
    "    job_title_fil.append(i.text)\n",
    "    \n",
    "#looping location to restrict the count to first 10 with indexing\n",
    "for i in location[0:10]:\n",
    "    job_location_fil.append(i.text)\n",
    "\n",
    "#looping compny name to restrict the count to first 10 with indexing\n",
    "for i in company[0:10]:\n",
    "    company_name_fil.append(i.text)\n",
    "    \n",
    "#appending url of each job to retrieve full description for each job\n",
    "for i in experience[0:10]:\n",
    "    experience_required_fil.append(i.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_job=pd.DataFrame({})\n",
    "filtered_job['job_title_fil']=job_title_fil\n",
    "filtered_job['job_location_fil']=job_location_fil\n",
    "filtered_job['company_name_fil']=company_name_fil\n",
    "filtered_job['experience_required_fil']=experience_required_fil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title_fil</th>\n",
       "      <th>job_location_fil</th>\n",
       "      <th>company_name_fil</th>\n",
       "      <th>experience_required_fil</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data analytics / Data scientist intern (work f...</td>\n",
       "      <td>Kolkata, Bangalore/Bengaluru, Delhi / NCR</td>\n",
       "      <td>TalkValley LLC</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chaayos is Looking For Data Scientist</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Chaayos (Sunshine Teahouse Pvt. Ltd.)</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist / Data Analyst -Business Analyst</td>\n",
       "      <td>Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...</td>\n",
       "      <td>Inflexion Analytix Private Limited</td>\n",
       "      <td>0-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Noida(Sector-59 Noida)</td>\n",
       "      <td>R Systems International Ltd.</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>We are hiring- Data Scientist +Python- Noida</td>\n",
       "      <td>Noida, Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>RANDSTAD INDIA PVT LTD</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, Delhi / NCR</td>\n",
       "      <td>Milliman India Pvt Ltd</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>NEC CORPORATION INDIA PRIVATE LIMITED</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst/Scientist Big Data, Statistical T...</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>The Search House (A Div of JSD Search House Pv...</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Business Analyst- Data Scientist</td>\n",
       "      <td>Noida, Gurgaon/Gurugram</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       job_title_fil  \\\n",
       "0  Data analytics / Data scientist intern (work f...   \n",
       "1              Chaayos is Looking For Data Scientist   \n",
       "2                                     Data Scientist   \n",
       "3    Data Scientist / Data Analyst -Business Analyst   \n",
       "4                              Junior Data Scientist   \n",
       "5       We are hiring- Data Scientist +Python- Noida   \n",
       "6                                     Data Scientist   \n",
       "7                                     Data Scientist   \n",
       "8  Data Analyst/Scientist Big Data, Statistical T...   \n",
       "9                   Business Analyst- Data Scientist   \n",
       "\n",
       "                                    job_location_fil  \\\n",
       "0          Kolkata, Bangalore/Bengaluru, Delhi / NCR   \n",
       "1                                          New Delhi   \n",
       "2      Mumbai, Gurgaon/Gurugram, Bangalore/Bengaluru   \n",
       "3  Mumbai, Hyderabad/Secunderabad, Pune, Gurgaon/...   \n",
       "4                             Noida(Sector-59 Noida)   \n",
       "5               Noida, Gurgaon/Gurugram, Delhi / NCR   \n",
       "6                      Gurgaon/Gurugram, Delhi / NCR   \n",
       "7                                              Noida   \n",
       "8                                   Gurgaon/Gurugram   \n",
       "9                            Noida, Gurgaon/Gurugram   \n",
       "\n",
       "                                    company_name_fil experience_required_fil  \n",
       "0                                     TalkValley LLC                 0-5 Yrs  \n",
       "1              Chaayos (Sunshine Teahouse Pvt. Ltd.)                 0-5 Yrs  \n",
       "2                                  Fractal Analytics                 3-7 Yrs  \n",
       "3                 Inflexion Analytix Private Limited                 0-3 Yrs  \n",
       "4                       R Systems International Ltd.                 3-5 Yrs  \n",
       "5                             RANDSTAD INDIA PVT LTD                 4-7 Yrs  \n",
       "6                             Milliman India Pvt Ltd                 2-5 Yrs  \n",
       "7              NEC CORPORATION INDIA PRIVATE LIMITED                 3-8 Yrs  \n",
       "8  The Search House (A Div of JSD Search House Pv...                 2-7 Yrs  \n",
       "9                                              Wipro                 2-5 Yrs  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_job.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXCERCISE IV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a python program to scrape data for first 10 job results for Data scientist\n",
    "Designation in Noida location. You have to scrape company_name, No. of days\n",
    "ago when job was posted, Rating of the company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating web driver object\n",
    "driver=webdriver.Chrome(executable_path='C:\\\\Users\\\\suren\\\\FlipRobo\\\\Micro-Credit-Project\\\\chromedriver.exe')\n",
    "\n",
    "#defining url\n",
    "url='https://www.glassdoor.co.in/Job/index.htm'\n",
    "\n",
    "#initialising driver\n",
    "driver.get(url)\n",
    "\n",
    "#maximizing the window\n",
    "driver.maximize_window()\n",
    "\n",
    "#clearing existing slectioinput and entering new job keyword\n",
    "key_element=driver.find_element_by_xpath('//input[@name=\"sc.keyword\"]')\n",
    "key_element.send_keys('Data Scientist')\n",
    "\n",
    "#entering location\n",
    "loc_element=driver.find_element_by_xpath('//input[@id=\"LocationSearch\"]')\n",
    "loc_element.clear()\n",
    "loc_element.send_keys('Noida')\n",
    "\n",
    "#clicking on search button\n",
    "driver.find_element(By.XPATH,'//button[@id=\"HeroSearchButton\"]').click()\n",
    "\n",
    "#selecting specific location as Noida to exclude near by cities if jobs are coming from near by cities as well\n",
    "time.sleep(3)\n",
    "try:\n",
    "    driver.find_element(By.XPATH,'//div[@label=\"All Cities\"]').click()\n",
    "    driver.find_element(By.XPATH,'//div[@id=\"PrimaryDropdown\"]//span[contains(text(),\"Noida\")]').click()\n",
    "except NoSuchElementException as s:\n",
    "    print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an empty list to scrape the details in a list form\n",
    "gd_company_name=[]\n",
    "gd_no_days=[]\n",
    "gd_company_rating=[]\n",
    "\n",
    "#scrapping company name and storing it into a list\n",
    "cn_wb=driver.find_elements(By.XPATH,'//div[@class=\"d-flex justify-content-between align-items-start\"]')\n",
    "\n",
    "#looping number of companies required\n",
    "for i in cn_wb[0:10]:\n",
    "    gd_company_name.append(i.text)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Salasar New Age Technologies',\n",
       " 'Crowe',\n",
       " 'Data Patterns',\n",
       " 'Biz2Credit Inc',\n",
       " 'Ericsson',\n",
       " 'Priority Vendor',\n",
       " 'Techlive',\n",
       " 'Lantern Digital Services',\n",
       " 'Gauge Data Solutions',\n",
       " 'xtLytics']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd_company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping age of post and appending it to the list\n",
    "age_wb=driver.find_elements(By.XPATH,'//div[@data-test=\"job-age\"]')\n",
    "\n",
    "#looping number of companies required\n",
    "for i in age_wb[0:10]:\n",
    "    gd_no_days.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['24h', '15d', '3d', '23d', '', '14d', '21d', '9d', '14d', '1d']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd_no_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping age of post and appending it to the list\n",
    "rate=driver.find_elements(By.XPATH,'//span[@class=\"css-19pjha7 e1cjmv6j1\"]')\n",
    "#looping number of companies required\n",
    "for i in rate[0:10]:\n",
    "    gd_company_rating.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3.8', '3.0', '3.7', '4.1', '3.7', '5.0', '3.5', '3.0', '3.8', '3.7']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gd_company_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "glassdoor=pd.DataFrame({})\n",
    "glassdoor['company_name']=gd_company_name\n",
    "glassdoor['Age pf add']=gd_no_days\n",
    "glassdoor['Rating']=gd_company_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>Age pf add</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Salasar New Age Technologies</td>\n",
       "      <td>24h</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crowe</td>\n",
       "      <td>15d</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Patterns</td>\n",
       "      <td>3d</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Biz2Credit Inc</td>\n",
       "      <td>23d</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ericsson</td>\n",
       "      <td></td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Priority Vendor</td>\n",
       "      <td>14d</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Techlive</td>\n",
       "      <td>21d</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lantern Digital Services</td>\n",
       "      <td>9d</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gauge Data Solutions</td>\n",
       "      <td>14d</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>xtLytics</td>\n",
       "      <td>1d</td>\n",
       "      <td>3.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   company_name Age pf add Rating\n",
       "0  Salasar New Age Technologies        24h    3.8\n",
       "1                         Crowe        15d    3.0\n",
       "2                 Data Patterns         3d    3.7\n",
       "3                Biz2Credit Inc        23d    4.1\n",
       "4                      Ericsson               3.7\n",
       "5               Priority Vendor        14d    5.0\n",
       "6                      Techlive        21d    3.5\n",
       "7      Lantern Digital Services         9d    3.0\n",
       "8          Gauge Data Solutions        14d    3.8\n",
       "9                      xtLytics         1d    3.7"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glassdoor.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXCERCISE V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a python program to scrape the salary data for Data Scientist designation\n",
    "in Noida location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating web driver object\n",
    "driver=webdriver.Chrome(executable_path='C:\\\\Users\\\\suren\\\\FlipRobo\\\\Micro-Credit-Project\\\\chromedriver.exe')\n",
    "\n",
    "#defining url\n",
    "url='https://www.glassdoor.co.in/Salaries/index.htm'\n",
    "\n",
    "#initialising driver\n",
    "driver.get(url)\n",
    "\n",
    "#maximizing the window\n",
    "driver.maximize_window()\n",
    "\n",
    "#clearing existing slectioinput and entering new job keyword\n",
    "key_element=driver.find_element_by_xpath('//input[@name=\"sc.keyword\"]')\n",
    "key_element.send_keys('Data Scientist')\n",
    "\n",
    "#entering location\n",
    "loc_element=driver.find_element_by_xpath('//input[@id=\"LocationSearch\"]')\n",
    "loc_element.clear()\n",
    "loc_element.send_keys('Noida')\n",
    "\n",
    "#clicking on search button\n",
    "driver.find_element(By.XPATH,'//button[@id=\"HeroSearchButton\"]').click()\n",
    "\n",
    "#selecting specific location as Noida to exclude near by cities if jobs aare coming from \n",
    "#time.sleep(3)\n",
    "#driver.find_element(By.XPATH,'//div[@label=\"All Cities\"]').click()\n",
    "#driver.find_element(By.XPATH,'//div[@id=\"PrimaryDropdown\"]//span[contains(text(),\"Noida\")]').click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an empty list to scrape the details in a list form\n",
    "Company_name=[]\n",
    "Number_of_salaries=[]\n",
    "Average_salary=[]\n",
    "Min_salary=[]\n",
    "Max_Salary=[]\n",
    "\n",
    "#creating web element objevt for reequired details\n",
    "com_name=driver.find_elements(By.XPATH,'//div[@class=\"py css-17435dd\"]//div//div[2]/h3/a')\n",
    "no_sal=driver.find_elements(By.XPATH,'//div[@class=\"col-12 col-lg-auto\"]')\n",
    "av_sal=driver.find_elements(By.XPATH,'//div[@class=\"col-12 col-lg-4 px-lg-0 d-flex align-items-baseline\"]/h3')\n",
    "min_sal=driver.find_elements(By.XPATH,'//div[@class=\"d-flex mt-xxsm css-79elbk epuxyqn0\"]/p[1]')\n",
    "max_sal=driver.find_elements(By.XPATH,'//div[@class=\"d-flex mt-xxsm css-79elbk epuxyqn0\"]/p[2]')\n",
    "\n",
    "#Looping company name\n",
    "for i in com_name[0:10]:\n",
    "    Company_name.append(i.text)\n",
    "    \n",
    "#Looping number of salaries \n",
    "for i in no_sal[0:10]:\n",
    "    Number_of_salaries.append(i.text)\n",
    "\n",
    "#Looping Average salary\n",
    "for i in av_sal[0:10]:\n",
    "    Average_salary.append(i.text)\n",
    "\n",
    "#looping minimum salary\n",
    "for i in min_sal[0:10]:\n",
    "    Min_salary.append(i.text)\n",
    "\n",
    "#looping maximum salary\n",
    "for i in max_sal[0:10]:\n",
    "    Max_Salary.append(i.text)\n",
    "    \n",
    "driver.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating dta frame with the details scrapped\n",
    "glassdoor_salary=pd.DataFrame({})\n",
    "glassdoor_salary['Company_name']=Company_name\n",
    "glassdoor_salary['Number_of_salaries']=Number_of_salaries\n",
    "glassdoor_salary['Average_salary']=Average_salary\n",
    "glassdoor_salary['Min_salary']=Min_salary\n",
    "glassdoor_salary['Max_Salary']=Max_Salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Number_of_salaries</th>\n",
       "      <th>Average_salary</th>\n",
       "      <th>Min_salary</th>\n",
       "      <th>Max_Salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Company_name, Number_of_salaries, Average_salary, Min_salary, Max_Salary]\n",
       "Index: []"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glassdoor_salary.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXCERCISE VI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape data of first 100 sunglasses listings on flipkart.com. You have to\n",
    "scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. Discount %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating web driver object\n",
    "driver=webdriver.Chrome(executable_path='C:\\\\Users\\\\suren\\\\FlipRobo\\\\Micro-Credit-Project\\\\chromedriver.exe')\n",
    "\n",
    "#defining url\n",
    "url='https://www.flipkart.com/'\n",
    "\n",
    "#initialising driver\n",
    "driver.get(url)\n",
    "\n",
    "#maximizing the window\n",
    "driver.maximize_window()\n",
    "\n",
    "#checking of the log in pop up is coming, if its comes closing the same\n",
    "try:\n",
    "    driver.find_element(By.XPATH,'//button[@class=\"_2KpZ6l _2doB4z\"]').click()\n",
    "\n",
    "except:\n",
    "    print(' no pop up')\n",
    "\n",
    "#entering the product to search\n",
    "driver.find_element(By.XPATH,'//input[@title=\"Search for products, brands and more\"]').send_keys('sunglasses')\n",
    "\n",
    "#clicking on search button\n",
    "driver.find_element_by_xpath('//button[@class=\"L0Z3Pu\"]').click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list to store the scrapped data\n",
    "brand=[]\n",
    "product_description=[]\n",
    "price=[]\n",
    "Discount=[]\n",
    "\n",
    "#defining  variable for maximu number of data required\n",
    "data_req=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looping each data ppend in  loop when length of a list is below 100\n",
    "while len(brand)<data_req:\n",
    "    \n",
    "    #storing xpth into elements(This can be done out side loop as well)\n",
    "    brand_ele=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    prod_ele=driver.find_elements(By.XPATH,'//div[@class=\"_2B099V\"]/a[1]')\n",
    "    pri_ele=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    dis_ele=driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]/span')\n",
    "    next_ele=driver.find_element(By.XPATH,'//span[contains(text(), \"Next\")]')\n",
    "    \n",
    "    #looing brands and appending till 100\n",
    "    for i in brand_ele:\n",
    "        if len(brand)==data_req:\n",
    "            break\n",
    "        brand.append(i.text)\n",
    "\n",
    "    #looing product name and appending till 100\n",
    "    for i in prod_ele:\n",
    "        if len(product_description)==data_req:\n",
    "            break\n",
    "        product_description.append(i.text)\n",
    "        \n",
    "    #looing price and appending till 100\n",
    "    for i in pri_ele:\n",
    "        if len(price)==data_req:\n",
    "            break\n",
    "        price.append(i.text)\n",
    "    \n",
    "    #looing discount and appending till 100\n",
    "    for i in dis_ele:\n",
    "        if len(Discount)==data_req:\n",
    "            break\n",
    "        Discount.append(i.text)\n",
    "    \n",
    "#checking if the required number of data are scrapped before clicking on next link if the reequired data is scrapped closing the browser\n",
    "    if len(brand)!=100:\n",
    "        time.sleep(3)\n",
    "        next_ele.click()\n",
    "        time.sleep(5)\n",
    "    else:\n",
    "        driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sunglass=pd.DataFrame({})\n",
    "sunglass['brand']=brand\n",
    "sunglass['Product']=product_description\n",
    "sunglass['price']=price\n",
    "sunglass['Discount']=Discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>Product</th>\n",
       "      <th>price</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (54)</td>\n",
       "      <td>₹237</td>\n",
       "      <td>85% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kingsunglasses</td>\n",
       "      <td>Mirrored, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹299</td>\n",
       "      <td>88% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>₹570</td>\n",
       "      <td>28% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>₹621</td>\n",
       "      <td>22% off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Aviator Sunglasses (58)</td>\n",
       "      <td>₹331</td>\n",
       "      <td>87% off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            brand                                            Product price  \\\n",
       "0          PIRASO              UV Protection Aviator Sunglasses (54)  ₹237   \n",
       "1  kingsunglasses  Mirrored, UV Protection Wayfarer Sunglasses (F...  ₹299   \n",
       "2        Fastrack   UV Protection Rectangular Sunglasses (Free Size)  ₹570   \n",
       "3        Fastrack  Gradient, UV Protection Wayfarer Sunglasses (F...  ₹621   \n",
       "4          PIRASO              UV Protection Aviator Sunglasses (58)  ₹331   \n",
       "\n",
       "  Discount  \n",
       "0  85% off  \n",
       "1  88% off  \n",
       "2  28% off  \n",
       "3  22% off  \n",
       "4  87% off  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sunglass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXCERCISE VII"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link\n",
    "\n",
    "1. Rating\n",
    "2. Review_summary\n",
    "3. Full review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating web driver object\n",
    "driver=webdriver.Chrome(executable_path='C:\\\\Users\\\\suren\\\\FlipRobo\\\\Micro-Credit-Project\\\\chromedriver.exe')\n",
    "\n",
    "#defining url\n",
    "url='https://www.flipkart.com/apple-iphone-11-black-64-gb-includes-earpods-power-adapter/p/itm0f37c2240b217?pid=MOBFKCTSVZAXUHGR&lid=LSTMOBFKCTSVZAXUHGREPBFGI&marketplace'\n",
    "\n",
    "#initialising driver\n",
    "driver.get(url)\n",
    "\n",
    "#maximizing the window\n",
    "driver.maximize_window()\n",
    "\n",
    "#getting all reviews\n",
    "driver.find_element(By.XPATH,'//div[@class=\"_3UAT2v _16PBlm\"]').click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an empty list to store the data we scrap\n",
    "Rating=[]\n",
    "Review_summary=[]\n",
    "Full_review=[]\n",
    "no_of_reviews=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#defining locators for each feaatur we need\n",
    "\n",
    "\n",
    "while len(Rating)<100:\n",
    "    \n",
    "    #since the page is dynamic, nodes are not sme on different pges, to handle the stale exception located elements in try block\n",
    "    try:\n",
    "        rate_ele=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "        rev_sum_ele=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "        rev_ele=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]/div/div')\n",
    "        next_ele=driver.find_element(By.XPATH,'//span[contains(text(), \"Next\")]')\n",
    "    except StaleElementReferenceExceptions as e:\n",
    "        print('Exceptions occured' , e)\n",
    "        \n",
    "    #Appending Rating feature untill 100\n",
    "    for i in rate_ele:\n",
    "        if len(Rating)==100:\n",
    "            break\n",
    "        Rating.append(i.text)\n",
    "        \n",
    "    #Appending review summary feature untill 100\n",
    "    for i in rev_sum_ele:\n",
    "        if len(Review_summary)==100:\n",
    "            break\n",
    "        Review_summary.append(i.text)\n",
    "        \n",
    "    #Appending review summary feature untill 100    \n",
    "    for i in rev_ele:\n",
    "        if len(Full_review)==100:\n",
    "            break\n",
    "        Full_review.append(i.text)\n",
    "     \n",
    "    #restring the next page navigation in if block to stop navigating to next pages as soon as we get  data\n",
    "    if len(Rating)!=100:\n",
    "        #since i got click intercepted error tried handling the exception in try block\n",
    "        try:\n",
    "            time.sleep(3)\n",
    "            next_ele.click()\n",
    "            time.sleep(5)\n",
    "        except ElementClickInterceptedException as c:\n",
    "            print('Exception occured', c)\n",
    "    else:\n",
    "        driver.close()\n",
    "\n",
    "\n",
    "len(Rating)\n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "iphone_review=pd.DataFrame({})\n",
    "iphone_review['Rating']=Rating\n",
    "iphone_review['Review_summary']=Review_summary\n",
    "iphone_review['Full_review']=Full_review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_summary</th>\n",
       "      <th>Full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Super!</td>\n",
       "      <td>This is my first ever iPhone.\\nAnd I truly don...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Awesome</td>\n",
       "      <td>Can’t beat the software and hardware integrati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>4</td>\n",
       "      <td>Excellent</td>\n",
       "      <td>Value for money product. This iphone 11 is rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>4</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>Thanks Flipkart For this amazing deal! I had a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>4</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>I genuinely liked it. One of the best mobile p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating      Review_summary  \\\n",
       "95      5              Super!   \n",
       "96      5             Awesome   \n",
       "97      4           Excellent   \n",
       "98      4  Highly recommended   \n",
       "99      4           Wonderful   \n",
       "\n",
       "                                          Full_review  \n",
       "95  This is my first ever iPhone.\\nAnd I truly don...  \n",
       "96  Can’t beat the software and hardware integrati...  \n",
       "97  Value for money product. This iphone 11 is rea...  \n",
       "98  Thanks Flipkart For this amazing deal! I had a...  \n",
       "99  I genuinely liked it. One of the best mobile p...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iphone_review.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXCERCISE VIII"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape data for first 100 sneakers you find when you visit flipkart.com and\n",
    "search for “sneakers” in the search field\n",
    "\n",
    "\n",
    "You have to scrape 4 attributes of each sneaker :\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "4. discount %\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code written for Excersie VI should work heree as well only change is the procduct we search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating web driver object\n",
    "driver=webdriver.Chrome(executable_path='C:\\\\Users\\\\suren\\\\FlipRobo\\\\Micro-Credit-Project\\\\chromedriver.exe')\n",
    "\n",
    "#defining url\n",
    "url='https://www.flipkart.com/'\n",
    "\n",
    "#initialising driver\n",
    "driver.get(url)\n",
    "\n",
    "#maximizing the window\n",
    "driver.maximize_window()\n",
    "\n",
    "#checking of the log in pop up is coming, if its comes closing the same\n",
    "try:\n",
    "    driver.find_element(By.XPATH,'//button[@class=\"_2KpZ6l _2doB4z\"]').click()\n",
    "\n",
    "except:\n",
    "    print(' no pop up')\n",
    "\n",
    "#entering the product to search\n",
    "driver.find_element(By.XPATH,'//input[@title=\"Search for products, brands and more\"]').send_keys('sneakers')\n",
    "\n",
    "#clicking on search button\n",
    "driver.find_element_by_xpath('//button[@class=\"L0Z3Pu\"]').click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating empty list to store the scrapped data\n",
    "brand=[]\n",
    "product_description=[]\n",
    "price=[]\n",
    "Discount=[]\n",
    "\n",
    "#defining  variable for maximu number of data required\n",
    "data_req=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looping each data ppend in  loop when length of a list is below 100\n",
    "while len(brand)<data_req:\n",
    "    \n",
    "    #storing xpth into elements(This can be done out side loop as well)\n",
    "    brand_ele=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    prod_ele=driver.find_elements(By.XPATH,'//div[@class=\"_2B099V\"]/a[1]')\n",
    "    pri_ele=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    dis_ele=driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]/span')\n",
    "    next_ele=driver.find_element(By.XPATH,'//span[contains(text(), \"Next\")]')\n",
    "    \n",
    "    #looing brands and appending till 100\n",
    "    for i in brand_ele:\n",
    "        if len(brand)==data_req:\n",
    "            break\n",
    "        brand.append(i.text)\n",
    "\n",
    "    #looing product name and appending till 100\n",
    "    for i in prod_ele:\n",
    "        if len(product_description)==data_req:\n",
    "            break\n",
    "        product_description.append(i.text)\n",
    "        \n",
    "    #looing price and appending till 100\n",
    "    for i in pri_ele:\n",
    "        if len(price)==data_req:\n",
    "            break\n",
    "        price.append(i.text)\n",
    "    \n",
    "    #looing discount and appending till 100\n",
    "    for i in dis_ele:\n",
    "        if len(Discount)==data_req:\n",
    "            break\n",
    "        Discount.append(i.text)\n",
    "    \n",
    "#checking if the required number of data are scrapped before clicking on next link if the reequired data is scrapped closing the browser\n",
    "    if len(brand)!=100:\n",
    "        time.sleep(3)\n",
    "        next_ele.click()\n",
    "        time.sleep(5)\n",
    "    else:\n",
    "        driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100, 100)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brand), len(product_description), len(price), len(Discount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "sneakers=pd.DataFrame({})\n",
    "sneakers['brand']=brand\n",
    "sneakers['Product']=product_description\n",
    "sneakers['price']=price\n",
    "sneakers['Discount %']=Discount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>Product</th>\n",
       "      <th>price</th>\n",
       "      <th>Discount %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chevit</td>\n",
       "      <td>Unique &amp; Perfect Collection Combo Pack of 02 S...</td>\n",
       "      <td>₹448</td>\n",
       "      <td>₹1050 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>India hub</td>\n",
       "      <td>Fashionable casual sneakers shoes Sneakers For...</td>\n",
       "      <td>₹389</td>\n",
       "      <td>₹2610 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ORICUM</td>\n",
       "      <td>Combo pack of 2 casual sneaker shoes for men S...</td>\n",
       "      <td>₹377</td>\n",
       "      <td>₹621 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KULP</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹399</td>\n",
       "      <td>₹600 off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CALCADOS</td>\n",
       "      <td>Modern Trendy Shoes Combo pack of 4 Sneakers F...</td>\n",
       "      <td>₹748</td>\n",
       "      <td>₹1248 off</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       brand                                            Product price  \\\n",
       "0     Chevit  Unique & Perfect Collection Combo Pack of 02 S...  ₹448   \n",
       "1  India hub  Fashionable casual sneakers shoes Sneakers For...  ₹389   \n",
       "2     ORICUM  Combo pack of 2 casual sneaker shoes for men S...  ₹377   \n",
       "3       KULP                                   Sneakers For Men  ₹399   \n",
       "4   CALCADOS  Modern Trendy Shoes Combo pack of 4 Sneakers F...  ₹748   \n",
       "\n",
       "  Discount %  \n",
       "0  ₹1050 off  \n",
       "1  ₹2610 off  \n",
       "2   ₹621 off  \n",
       "3   ₹600 off  \n",
       "4  ₹1248 off  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sneakers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXCERCISE IX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to the link - https://www.myntra.com/shoes\n",
    "Set Price filter to “Rs. 6649 to Rs. 13099” ,\n",
    "Color filter to “Black”, as shown in\n",
    "the below image\n",
    "\n",
    "scrape\n",
    "\n",
    "brand               \n",
    "product_description                    \n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating web driver object\n",
    "driver=webdriver.Chrome(executable_path='C:\\\\Users\\\\suren\\\\FlipRobo\\\\Micro-Credit-Project\\\\chromedriver.exe')\n",
    "\n",
    "#defining url\n",
    "url='https://www.myntra.com/shoes'\n",
    "\n",
    "#initialising driver\n",
    "driver.get(url)\n",
    "\n",
    "#maximizing the window\n",
    "driver.maximize_window()\n",
    "\n",
    "#applying price filter\n",
    "price_button = driver.find_element_by_xpath(\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label/div\")\n",
    "price_button.click()\n",
    "\n",
    "#applying color filter\n",
    "driver.find_element(By.XPATH,'//span[@data-colorhex=\"black\"]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating an empty lst for each featur we need\n",
    "brand=[]\n",
    "product=[]\n",
    "price=[]\n",
    "\n",
    "no_of_data=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "while len(brand) < no_of_data:\n",
    "    time.sleep(5)\n",
    "    #since i got stale element  exception, to handle the stale exception located elements in try block\n",
    "    try:\n",
    "        brand_ele=driver.find_elements(By.XPATH,'//h3[@class=\"product-brand\"]')\n",
    "        product_ele=driver.find_elements(By.XPATH,'//h4[@class=\"product-product\"]')\n",
    "        price_ele=driver.find_elements(By.XPATH,'//div[@class=\"product-price\"]/span[1]')\n",
    "    except StaleElementReferenceExceptions as e:\n",
    "        print('Exceptions occured' , e)\n",
    "    \n",
    "    #appending brand details\n",
    "    for i in brand_ele:\n",
    "        brand.append(i.text)\n",
    "    #appending product details\n",
    "    for i in product_ele:\n",
    "        product.append(i.text)\n",
    "    #appending price details and using functions in string to extract the data needed\n",
    "    for i in price_ele:\n",
    "        splitted_price=i.text.split(' ')\n",
    "        fin_price=splitted_price[1].replace('Rs.','')\n",
    "        final_price='Rs.'+fin_price\n",
    "        price.append(final_price)\n",
    "        \n",
    "    if len(brand)<no_of_data:\n",
    "        driver.find_element(By.XPATH,'//a[@rel=\"next\"]').click()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100, 100)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(brand), len(product), len(price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "myntra=pd.DataFrame({})\n",
    "myntra['brand']=brand\n",
    "myntra['product']=product\n",
    "myntra['price']=price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>brand</th>\n",
       "      <th>product</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MENGLER</td>\n",
       "      <td>Men Walking Shoes</td>\n",
       "      <td>Rs.645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nabaiji By Decathlon</td>\n",
       "      <td>Unisex Aqua Aerobics Shoes</td>\n",
       "      <td>Rs.899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASICS</td>\n",
       "      <td>Kids Solid Running Shoes</td>\n",
       "      <td>Rs.758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nike</td>\n",
       "      <td>Men SPEEDREP Training Shoes</td>\n",
       "      <td>Rs.5756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Go Flex 2 Contort Walking</td>\n",
       "      <td>Rs.4399</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  brand                      product    price\n",
       "0               MENGLER            Men Walking Shoes   Rs.645\n",
       "1  Nabaiji By Decathlon   Unisex Aqua Aerobics Shoes   Rs.899\n",
       "2                 ASICS     Kids Solid Running Shoes   Rs.758\n",
       "3                  Nike  Men SPEEDREP Training Shoes  Rs.5756\n",
       "4              Skechers    Go Flex 2 Contort Walking  Rs.4399"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myntra.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXCERCISE X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes\n",
    "for each laptop:\n",
    "1. title\n",
    "2. Ratings\n",
    "3. Price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating web driver object\n",
    "driver=webdriver.Chrome(executable_path='C:\\\\Users\\\\suren\\\\FlipRobo\\\\Micro-Credit-Project\\\\chromedriver.exe')\n",
    "\n",
    "#defining url\n",
    "url='https://www.amazon.in/'\n",
    "\n",
    "#initialising driver\n",
    "driver.get(url)\n",
    "\n",
    "#maximizing the window\n",
    "driver.maximize_window()\n",
    "\n",
    "#entering search items in the search bar\n",
    "driver.find_element(By.XPATH,'//input[@id=\"twotabsearchtextbox\"]').send_keys('Laptop')\n",
    "\n",
    "#Clicking on search button\n",
    "driver.find_element(By.XPATH,'//input[@id=\"nav-search-submit-button\"]').click()\n",
    "\n",
    "\n",
    "#clicking on i9\n",
    "try:\n",
    "    driver.find_element(By.XPATH,'//*[@id=\"p_n_feature_thirteen_browse-bin/16757432031\"]/span/a/span').click()\n",
    "except NoSuchElementExceptions as e:\n",
    "    print('Exception occured',e)\n",
    "    driver.find_element(By.XPATH,'//span[contains(text(),\"Intel Core i9\")]').click()\n",
    "    \n",
    "    \n",
    "time.sleep(3)\n",
    "\n",
    "try:\n",
    "    driver.find_element(By.XPATH,'//*[@id=\"p_n_feature_thirteen_browse-bin/12598163031\"]/span/a/span').click()\n",
    "except NoSuchElementExceptions as e:\n",
    "    print('Exception occured',e)\n",
    "    driver.find_element(By.XPATH,'//span[contains(text(),\"Intel Core i7\")]').click()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating locators\n",
    "title_ele=driver.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "rating_ele=driver.find_elements(By.XPATH,'//div[@class=\"a-row a-size-small\"]/span[1]')\n",
    "price_ele=driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "title=[]\n",
    "rating=[]\n",
    "price=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#appending title details\n",
    "for i in title_ele[0:10]:\n",
    "    title.append(i.text)\n",
    "    \n",
    "#appending rating details\n",
    "for i in rating_ele[0:10]:\n",
    "    rating.append(i.get_attribute('aria-label'))\n",
    "\n",
    "#appending price details\n",
    "for i in price_ele[0:10]:\n",
    "    price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 10, 10)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title), len(rating), len(price),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "laptop=pd.DataFrame({})\n",
    "laptop['title']=title\n",
    "laptop['rating']=rating\n",
    "laptop['price']=price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lenovo Yoga 7 11th Gen Intel Core i7 14\" (35.5...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>97,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenovo Yoga Slim 7 10th Gen Intel Core i7 14 i...</td>\n",
       "      <td>3.3 out of 5 stars</td>\n",
       "      <td>83,902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo Yoga 7 11th Gen Intel Core i7 14\" (35.5...</td>\n",
       "      <td>4.2 out of 5 stars</td>\n",
       "      <td>97,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mi Notebook Horizon Edition 14 Intel Core i5-1...</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "      <td>54,999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HP Pavilion (2021) Thin &amp; Light 11th Gen Core ...</td>\n",
       "      <td>4.5 out of 5 stars</td>\n",
       "      <td>84,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS ROG Zephyrus Duo 15, 15.6\" 4K UHD, Intel ...</td>\n",
       "      <td>3.8 out of 5 stars</td>\n",
       "      <td>2,69,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP 14 Thin &amp; Light 14\" (35.56cms) FHD Laptop (...</td>\n",
       "      <td>4.7 out of 5 stars</td>\n",
       "      <td>88,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>MSI Gaming GL65 Leopard , Intel 9th Gen. i7-97...</td>\n",
       "      <td>4.4 out of 5 stars</td>\n",
       "      <td>71,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lenovo Ideapad 5 Intel i7 11th Gen 15.6\" Thin ...</td>\n",
       "      <td>5.0 out of 5 stars</td>\n",
       "      <td>78,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Life Digital Laptop 15.6-inch (39.62 cms) (Int...</td>\n",
       "      <td>3.1 out of 5 stars</td>\n",
       "      <td>26,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title              rating  \\\n",
       "0  Lenovo Yoga 7 11th Gen Intel Core i7 14\" (35.5...  4.2 out of 5 stars   \n",
       "1  Lenovo Yoga Slim 7 10th Gen Intel Core i7 14 i...  3.3 out of 5 stars   \n",
       "2  Lenovo Yoga 7 11th Gen Intel Core i7 14\" (35.5...  4.2 out of 5 stars   \n",
       "3  Mi Notebook Horizon Edition 14 Intel Core i5-1...  4.4 out of 5 stars   \n",
       "4  HP Pavilion (2021) Thin & Light 11th Gen Core ...  4.5 out of 5 stars   \n",
       "5  ASUS ROG Zephyrus Duo 15, 15.6\" 4K UHD, Intel ...  3.8 out of 5 stars   \n",
       "6  HP 14 Thin & Light 14\" (35.56cms) FHD Laptop (...  4.7 out of 5 stars   \n",
       "7  MSI Gaming GL65 Leopard , Intel 9th Gen. i7-97...  4.4 out of 5 stars   \n",
       "8  Lenovo Ideapad 5 Intel i7 11th Gen 15.6\" Thin ...  5.0 out of 5 stars   \n",
       "9  Life Digital Laptop 15.6-inch (39.62 cms) (Int...  3.1 out of 5 stars   \n",
       "\n",
       "      price  \n",
       "0    97,990  \n",
       "1    83,902  \n",
       "2    97,990  \n",
       "3    54,999  \n",
       "4    84,990  \n",
       "5  2,69,990  \n",
       "6    88,990  \n",
       "7    71,990  \n",
       "8    78,990  \n",
       "9    26,990  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptop.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
